{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c7bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from collections import defaultdict\n",
    "import gc, pickle, os, time\n",
    "import random\n",
    "\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names, combined_dnn_input\n",
    "from deepctr_torch.models.basemodel import BaseModel\n",
    "from deepctr_torch.layers.interaction import FM, BiInteractionPooling\n",
    "from deepctr_torch.layers import DNN, concat_fun, InteractingLayer\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import Dataset, DataLoader,RandomSampler, SequentialSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import warnings\n",
    "from collections import Counter \n",
    "import sys\n",
    "BASE_DIR = os.getcwd()\n",
    "sys.path.append(os.path.join(BASE_DIR, 'model'))\n",
    "from mmoe import MMOE_DNN_v1, MMOE_DNN_v2\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffcb56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, \n",
    "                 sparse_cols, dense_cols, \n",
    "                 word2id_list, \n",
    "                 uid_2_emb=None, fid_2_emb=None, aid_2_emb=None,\n",
    "                 manual_fea=None,\n",
    "                 ):\n",
    "        self.sparse_features = df[sparse_cols].values\n",
    "        self.dense_features = df[dense_cols].values\n",
    "        self.dates = df['date_'].values\n",
    "        \n",
    "        self.word2id_list = word2id_list\n",
    "        \n",
    "        self.uid_2_emb = uid_2_emb\n",
    "        self.fid_2_emb = fid_2_emb\n",
    "        self.aid_2_emb = aid_2_emb\n",
    "        \n",
    "        self.manual_fea = manual_fea\n",
    "        self.mf_size = [41, 30, 33, 32, 32, 32, 32]\n",
    "        self.df_len = df.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df_len\n",
    "\n",
    "    def __getitem__(self, i):  \n",
    "        # 标签信息，日期信息\n",
    "        date_ = self.dates[i]\n",
    "        \n",
    "        # Sparse特征\n",
    "        sparse_f = self.sparse_features[i]\n",
    "        uid, fid, device, aid, bgm_song, bgm_singer, kw1, tag1 = [int(x) for x in sparse_f]\n",
    "        \n",
    "        # Dense特征\n",
    "        dense_f = list(self.dense_features[i])\n",
    "        ## munual_fea\n",
    "        mf_list = [uid, fid, aid, bgm_song, bgm_singer, kw1, tag1]\n",
    "        \n",
    "        for idx, mf in enumerate(self.manual_fea):\n",
    "            dense_f.extend(list(mf.get((mf_list[idx], date_), [0.0]*self.mf_size[idx])))\n",
    "        \n",
    "        # Embedding特征\n",
    "        all_emb_f = list(self.uid_2_emb.get(uid, [0.0]*128))\n",
    "        all_emb_f.extend(list(self.fid_2_emb.get(fid, [0.0]*576)))\n",
    "        all_emb_f.extend(list(self.aid_2_emb.get(aid, [0.0]*64)))\n",
    "        \n",
    "        sparse_f = [self.word2id_list[idx].get(int(sparse_f[idx]), 1) for idx in range(len(sparse_f))]\n",
    "        return torch.FloatTensor(sparse_f + dense_f + all_emb_f)\n",
    "\n",
    "    \n",
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    pred_1, pred_2, pred_3, pred_4, pred_5, pred_6, pred_7 = [], [], [], [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for x in tqdm(test_loader):\n",
    "            y_pred = model(x.to(device))\n",
    "            pred_1.extend(y_pred[0].cpu().data.numpy().squeeze().tolist())\n",
    "            pred_2.extend(y_pred[1].cpu().data.numpy().squeeze().tolist())\n",
    "            pred_3.extend(y_pred[2].cpu().data.numpy().squeeze().tolist())\n",
    "            pred_4.extend(y_pred[3].cpu().data.numpy().squeeze().tolist())\n",
    "            pred_5.extend(y_pred[4].cpu().data.numpy().squeeze().tolist())\n",
    "            pred_6.extend(y_pred[5].cpu().data.numpy().squeeze().tolist())\n",
    "            pred_7.extend(y_pred[6].cpu().data.numpy().squeeze().tolist())\n",
    "    return (pred_1, pred_2, pred_3, pred_4, pred_5, pred_6, pred_7)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949cd04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a78eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c87638dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106444, 11)\n",
      "sparse_fea: 8, dense_fea: 5\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "args_test_path = \"/home/tione/notebook/wbdc2021/data/wedata/wechat_algo_data2/test_a.csv\"\n",
    "test = pd.read_csv(args_test_path)\n",
    "test['date_'] = 15\n",
    "# feed侧信息\n",
    "feed_info = pd.read_pickle(\"../data/features/feed_info.pkl\")\n",
    "feed_info.drop(columns=['all_keyword', 'all_tag'], inplace=True)\n",
    "    \n",
    "print(feed_info.shape)\n",
    "\n",
    "test = test.merge(feed_info, how='left', on=['feedid'])\n",
    "\n",
    "\n",
    "## 特征列的定义\n",
    "play_cols = ['is_finish', 'play_times', 'stay_times', 'play', 'stay']\n",
    "y_list = ['read_comment', 'like', 'click_avatar', 'favorite', 'forward', 'comment', 'follow']\n",
    "\n",
    "## 离散和连续特征\n",
    "sparse_features = ['userid', 'feedid', 'device', 'authorid', 'bgm_song_id', \n",
    "                       'bgm_singer_id', 'keyword1', 'tag1']\n",
    "dense_features = [x for x in test.columns if x not in sparse_features + ['date_'] + play_cols + y_list]\n",
    "print(\"sparse_fea: {}, dense_fea: {}\".format(len(sparse_features), len(dense_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1c7e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a8f2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feedid 106444 576\n",
      "userid 199999 128\n",
      "authorid 18788 64\n",
      "embedding features nums: 768\n"
     ]
    }
   ],
   "source": [
    "fid_2_emb, uid_2_emb, aid_2_emb = pickle.load(open(\"../data/features/fid_uid_aid_2_emb.pkl\", 'rb'))\n",
    "## 打印长度\n",
    "print('feedid', len(fid_2_emb), len(fid_2_emb[54042]))\n",
    "print('userid', len(uid_2_emb), len(uid_2_emb[0]))\n",
    "print('authorid', len(aid_2_emb), len(aid_2_emb[0]))\n",
    "\n",
    "emb_fea_nums = len(fid_2_emb[54042]) + len(uid_2_emb[0]) + len(aid_2_emb[0])\n",
    "print(\"embedding features nums: {}\".format(emb_fea_nums))\n",
    "\n",
    "## 手工特征\n",
    "manual_fea = pickle.load(open(\"../data/features/singer_col_stat_feas_test.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c67ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39122c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "542bd386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843213\n",
      "191779\n",
      "736591\n",
      "84500\n",
      "158013\n",
      "16766\n",
      "188669\n",
      "20989\n",
      "134256\n",
      "14819\n",
      "24661\n",
      "2478\n",
      "2494\n",
      "250\n",
      "Please check the latest version manually on https://pypi.org/project/deepctr-torch/#history\n"
     ]
    }
   ],
   "source": [
    "manual_fea_test = []\n",
    "for mf in manual_fea:\n",
    "    print(len(mf))\n",
    "    tmp = {k: v for k, v in mf.items() if k[1] == 15}\n",
    "    print(len(tmp))\n",
    "    manual_fea_test.append(tmp)\n",
    "pickle.dump(manual_fea_test, open(\"../data/features/singer_col_stat_feas_test.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444ec526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e0af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76a621fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## word2id list\n",
    "word2id_list = pickle.load(open(\"../data/features/all_word2id.pkl\", 'rb'))\n",
    "\n",
    "def get_loader(test, sparse_features, dense_features, word2id_list, \n",
    "               uid_2_emb, fid_2_emb, aid_2_emb, manual_fea):\n",
    "\n",
    "    ## 构建test_loader\n",
    "    test_dataset = MyDataset(test, sparse_features, dense_features,\n",
    "                            word2id_list=word2id_list, \n",
    "                            uid_2_emb=uid_2_emb, fid_2_emb=fid_2_emb, aid_2_emb=aid_2_emb,\n",
    "                            manual_fea=manual_fea)\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                           sampler=test_sampler,\n",
    "                           batch_size=20480, \n",
    "                           num_workers=14, \n",
    "                           pin_memory=True)\n",
    "    print(\"test loader size {}\".format(len(test_loader)))\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6186768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loader size 208\n"
     ]
    }
   ],
   "source": [
    "test_loader = get_loader(test, sparse_features, dense_features, word2id_list, \n",
    "                          uid_2_emb, fid_2_emb, aid_2_emb, manual_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "586e583c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0953ffa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual feature size 232\n",
      "all feature size 1013\n",
      "dense_fea_nums: 237\n",
      "fixlen_feature nums: 1013\n",
      "Feature nums is 1013\n",
      "cuda ready...\n"
     ]
    }
   ],
   "source": [
    "dense_fea_nums = sum([41, 30, 33, 32, 32, 32, 32])\n",
    "print(\"manual feature size {}\".format(dense_fea_nums))\n",
    "print(\"all feature size {}\".format(len(sparse_features) + len(dense_features) + dense_fea_nums + emb_fea_nums))\n",
    "emb_size = 48\n",
    "\n",
    "\n",
    "actions =  ['read_comment', 'like', 'click_avatar', 'favorite', 'forward', 'comment', 'follow']\n",
    "new_dense_features = dense_features + ['dense_{}'.format(i) for i in range(dense_fea_nums)]\n",
    "print(\"dense_fea_nums: {}\".format(len(new_dense_features)))\n",
    "# count #unique features for each sparse field,and record dense feature field name\n",
    "fixlen_feature_columns = [SparseFeat(feat, max(list(word2id_list[i].values()))+1, embedding_dim=emb_size)\n",
    "                              for i, feat in enumerate(sparse_features)] +\\\n",
    "                            [DenseFeat(feat, 1) for feat in new_dense_features + \n",
    "                             ['emb_{}'.format(i) for i in range(emb_fea_nums)]]\n",
    "\n",
    "\n",
    "print(\"fixlen_feature nums: {}\".format(len(fixlen_feature_columns)))\n",
    "# 所有特征列， dnn和linear都一样\n",
    "dnn_feature_columns = fixlen_feature_columns    # for DNN\n",
    "linear_feature_columns = fixlen_feature_columns   # for Embedding\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)   # all-特征名字\n",
    "print(\"Feature nums is {}\".format(len(feature_names)))\n",
    "    \n",
    "device = 'cpu'\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa14ab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please check the latest version manually on https://pypi.org/project/deepctr-torch/#history\n"
     ]
    }
   ],
   "source": [
    "## 定义模型，并开始推断  \n",
    "submit = test[['userid', 'feedid']]\n",
    "for col in actions:\n",
    "    submit[col] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "669d670a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [01:33<00:00,  2.22it/s]\n",
      "100%|██████████| 208/208 [01:33<00:00,  2.22it/s]\n",
      "100%|██████████| 208/208 [01:36<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 19s, sys: 36.5 s, total: 1min 55s\n",
      "Wall time: 4min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for model_date_ in [11, 13, 14]:\n",
    "    model = MMOE_DNN_v1(linear_feature_columns=linear_feature_columns, \n",
    "                     dnn_feature_columns=dnn_feature_columns,\n",
    "                     embed_dim=emb_size,\n",
    "                     use_fm=False,\n",
    "                     use_din=False,\n",
    "                     dnn_use_bn=True,\n",
    "                     dnn_hidden_units=(2048, 1024, 512, 256), \n",
    "                     init_std=0.0001, dnn_dropout=0.5, task='binary', \n",
    "                     l2_reg_embedding=1e-5, \n",
    "                     l2_reg_linear=0.0,\n",
    "                     l2_reg_dnn=0.0, \n",
    "                     device=device,\n",
    "                     num_tasks=7, num_experts=48, expert_dim=128)\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(\"../data/model/best_mmoe_model_date_is_{}.bin\".format(model_date_)))\n",
    "    model = torch.nn.DataParallel(model)\n",
    "        \n",
    "    test_preds = predict(model, test_loader, device)\n",
    "    for i in range(len(actions)):\n",
    "        submit[actions[i]] += np.round(test_preds[i], 8) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6f080e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f465d804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0f867a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loader size 208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [01:33<00:00,  2.22it/s]\n",
      "100%|██████████| 208/208 [01:30<00:00,  2.30it/s]\n",
      "100%|██████████| 208/208 [01:35<00:00,  2.19it/s]\n",
      "100%|██████████| 208/208 [01:32<00:00,  2.24it/s]\n",
      "100%|██████████| 208/208 [01:33<00:00,  2.23it/s]\n",
      "100%|██████████| 208/208 [01:35<00:00,  2.17it/s]\n",
      "100%|██████████| 208/208 [01:37<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 26s, sys: 1min 32s, total: 4min 59s\n",
      "Wall time: 11min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "del test_loader\n",
    "gc.collect()\n",
    "\n",
    "test_loader = get_loader(test, sparse_features, dense_features, word2id_list, \n",
    "                          uid_2_emb, fid_2_emb, aid_2_emb, manual_fea)\n",
    "\n",
    "for model_date_ in [6, 7, 8, 9, 10, 11, 12]:\n",
    "    model = MMOE_DNN_v2(linear_feature_columns=linear_feature_columns, \n",
    "                     dnn_feature_columns=dnn_feature_columns,\n",
    "                     embed_dim=emb_size,\n",
    "                     use_fm=True,\n",
    "                     use_din=False,\n",
    "                     dnn_use_bn=True,\n",
    "                     dnn_hidden_units=(2048, 1024, 512, 512), \n",
    "                     init_std=0.0001, dnn_dropout=0.5, task='binary', \n",
    "                     l2_reg_embedding=1e-5, \n",
    "                     l2_reg_linear=0.0,\n",
    "                     l2_reg_dnn=0.0, \n",
    "                     device=device,\n",
    "                     num_tasks=7, num_experts=32, expert_dim=256)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(\"../data/model/best_mmoe_model_date_is_{}_v2.bin\".format(model_date_)))\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    \n",
    "    test_preds = predict(model, test_loader, device)\n",
    "    for i in range(len(actions)):\n",
    "        submit[actions[i]] += np.round(test_preds[i], 8) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550262d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d07fcbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"../data/submission/result2.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54316c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9bf227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c491a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_wbdc2021_demo",
   "language": "python",
   "name": "conda_wbdc2021_demo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
